# Urban Heartbeat

Urban Heartbeat is an civic art project that explores the temporal identity and pulse of places in cities around the world. The project is part of the Data Canvas: Sense Your City competition, a DIY sensor project.

We will conduct several experiments based upon different environmental factors, such as pollution, noise, dust, and light. Each experiment explores a different factor using a different medium or visualization technique.

The primary goal of Urban Heartbeat is to empower the ability for any citizen to curate their own civic data search, and in turn, return customized search results in the form of information-rich, yet visually simplified format(s), or "pulses".


Our team began by building a series of audiovisual experiments for representing select environmental factors, such as pollution, noise, dust, and light.

[http://codepen.io/collection/DRzwQR/](View Experiments)

Over the course of three weeks, we explored, reviewed, and refined our experiments. The result is a web app/search engine that allows users to curate their own searches and compare pulses across 100 places in 7 international cities. Users will be invited to include select environmental factors as they find relevant to their search. Each environmental factor selected will contribute a “layer” onto a resulting urban pulse. As such, pulses will say as much about places as it will about people.

Start your own search now by visiting [http://urban-heartbeat.net/](http://urban-heartbeat.net/)

**View more detail about the three stages of our project process below, including Exploration, Experimentation, and Next Steps.

## PHASE I: EXPLORATION
### Data Canvas: Sense Your City Hackathon

Our team found each at SwissNexSF’s office at the [http://www.swissnexsanfrancisco.org/event/datacanvasd3/](Data Canvas: Sense Your City Hackathon). Drawn by our respective creative pitches, we swapped tables and discovered that we shared overlapping interests despite our various perspectives working with technology: front-end/back-end, UX/UI, and software/hardware development. We quickly noticed how we served as our very own test case,  aligning along a joint focus, yet with differing perspectives on what it was we were most excited to explore. Throughout the duration building our submission for Data Canvas (just short of 3 weeks), our interdisciplinary team continued to engage around the project by comparing findings and negotiating areas of interest - between back-end and front-end, and across locations and time zones.


### The Future of Data Visualization
As a collection of makers across interdisciplinary backgrounds, we share a wide range of influences and inspirations when it comes to data art-from the formation of utterly beautiful code to what we believe to be emerging innovations for the fields of data visualization, generative art, interactive media and technologies, and user experience design.

“It is not about triangles and Taurus's or motion trajectories, but about timing and patterns of interactivity, about triplets and cycles, subtractions and parallelism, switches and differentials...The architect with new computational tools is more often attracted to the visuals or behaviors of software environments than the invisible network architecture behind the screen."
–
Keller Easterling, American architect/urbanist/writer/teacher
(an excerpt from Organization Space..., MIT Press, 2001)

With the rapid increase of embedded products growing across microchips and macro urban scales, “big data” is moving beyond questions of “if” to “what then”? The focus is on generating “smarter” versions - not just smarter sensors, but smarter interfaces, or rather, smarter ways to engage a diverse set of participants with the increasingly complex data that surrounds them.

Urban<3Beat decided to approach this from the perspective of curation and “smarter aesthetics”. With access to 7 types of environmental sensors across 7 cities, we decided that the answer was to allow users the ability to navigate throughout these complex sets of data by curating simple searches as they found relevant:

 1. A Curatorial Search Engine: search through big data based on location(s) and layer(s) of interest
 2. Pulses of Place: view search results within an aesthetic format which reveals a simplified AT-A-GLANCE collection of what was searched for, or “smart aesthetics” which represent temporality and place
 3. Deeper Reads/Comparisons: follow diverse lines of inquiry if so desired by facilitating deeper dives into data, or comparative analysis


 Bigger data means a rise in the complexity of ''content'' for data visualization, but does not have to mean the same for its interface. We believe data visualizations will become increasingly searchable and dynamic, and as such, could inherit a kind of “smarter aesthetics” informed by considerations of time ( sneak a peek at [generative art](http://butdoesitfloat.com/index/filter/generative-art) and [https://processing.org/exhibition/](processing) and space [http://www.google.de/design/spec/material-design/introduction.html](material design) has added a whole new dimension).

#### Smarter Aesthetics: from Static to Dynamic

Another way to frame pervasive technologies is the discussion of a smarter “[http://en.wikipedia.org/wiki/Internet_of_Things](internet of things)” (IoT). Urban<3Beat is motivated by the opportunities for the human-centered version of IoT: “[http://www.wired.com/2014/11/the-internet-of-me/](the internet of me)”, where users might be empowered to better understand their patterns and desires with greater capabilities for personalization and analysis.

#### Local & Global: The Internet of Me
We were inspired to facilitate opportunities for better understanding self across local and global scales: explorations of individual interests, searches of local results, and side-side comparisons that bridge international boundaries.

## PHASE II: EXPERIMENTATION & ITERATION
After the hackathon, we began to explore our goals for data visualization from both ends (front-end UX and back-end code), and set out to experiment with ways for searching and displaying temporal, dynamic data.

The Back-End
After diving into GitHUB & d3, the options were clearly numerous. Luckily, our own goals (supported of course by a dose of “trial and error” from the front and back-ends) presented a set of constraints:

 1. Wherever possible, data should be represented by simple, dynamic, familiar visual forms
 2. Information which can be abstracted to more familiar visual forms of representation can live on a base layer for “Higher Level” reads
 3. Denser information can live on additional top layers for “deeper dives” (such as that accompanied by larger amounts of text or corresponding assets)
 4.  “Higher Level” data should work harmoniously as layers to create one visual “pulse” (with non-competing aesthetic logics of translation such as color, value, shape, etc.)

Collaboration and open-source is important to us, and so we shared our experiments, and encouraged others to fork their own. Visit our collection of data vis experiments below, hosted on '''CodePen'''.

[http://codepen.io/collection/DRzwQR/](View Experiments >)


<object data="../data/audio-visual-pulses.pdf" type="application/pdf" width="90%" height="59%">
  <p>It appears you don't have a PDF plugin for this browser.
  No biggie... you can <a href="../data/audio-visual-pulses.pdf">click here to
  download the PDF file.</a></p>
</object>

## Background
To state the obvious: cities are for people-not machines, not data scientists, not corporations.

Places, particularly broken down to the scale of a neighborhood, are really hard to quanitfy. Places are temporal and dynamic, changing dramatically over the course of a day, week, month, year.

The goal of our project where how to explore real-time data collection in a way that makes the process more transparent and intuitive to all citizens. To achieve this goal, we decided to explore different types of environmental data in different mediums, including light, sound, and visual design.

The next phase or our project would be to explore visualizations and interfaces on the sensors themselves that help people to understand what data is being sensed and learn about current environmental conditions such as pollution and weather.

[Insert mockup of sensor at a bus station]

----

"If something cannot fail, it is not experimental." Dan Deacon
